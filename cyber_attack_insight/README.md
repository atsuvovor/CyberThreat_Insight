# üõ°Ô∏è CyberThreat-Insight

## Attack Simulation & Stacked Anomaly Detection Platform

**Author:** Atsu Vovor
**Title:** Data & Analytics Consultant | Cybersecurity | AI Reporting
**Location:** Toronto, Canada

---

## üìå Executive Overview

**CyberThreat-Insight** is an **enterprise-grade cyber attack simulation, anomaly detection, and AI-assisted reporting platform** designed to support:

* Cyber risk scenario modeling
* Threat detection validation
* Executive and board-level reporting
* Model Risk Management (MRM)
* Regulatory and audit review readiness

The platform augments **real operational cybersecurity data** with **statistically governed attack simulations**, applies a **stacked ensemble anomaly detection model**, and produces **audit-ready outputs** for dashboards, reports, and AI-generated executive summaries.

This solution is intentionally designed to align with how **financial institutions, insurers, and regulated enterprises** evaluate analytics platforms during **Model Risk Committee, Internal Audit, and regulator reviews**.

---

## üß† Platform Capabilities at a Glance

* Multi-vector cyber attack simulation
* MITRE ATT&CK‚Äìaligned threat modeling
* Production-grade stacked anomaly detection
* ML-safe data engineering & inference
* Full data lineage & governance controls
* AI-assisted executive reporting
* Audit- and regulator-ready documentation

---

## üß© High-Level Architecture

```
External Data Sources (CSV / Google Drive)
            ‚îÇ
            ‚ñº
Operational Cybersecurity Dataset
            ‚îÇ
            ‚ñº
Attack Simulation Engine
(Phishing, Malware, DDoS, Insider, etc.)
            ‚îÇ
            ‚ñº
ML-Safe Data Sanitization & Validation
            ‚îÇ
            ‚ñº
Stacked Anomaly Detection Models
            ‚îÇ
            ‚ñº
Threat Scores & Anomaly Predictions
            ‚îÇ
            ‚ñº
Persisted Outputs (CSV / Dashboards / AI Reports)
```

---

## üß≠ MITRE ATT&CK‚ÄìMapped Architecture View

Each simulated attack is explicitly mapped to **MITRE ATT&CK tactics and techniques**, enabling:

* Threat coverage validation
* Blue-team alignment
* Regulatory traceability

| Attack Type    | MITRE Technique ID | Technique Name               |
| -------------- | ------------------ | ---------------------------- |
| Phishing       | T1566              | Phishing                     |
| Malware        | T1204              | User Execution               |
| Malware        | T1059              | Command & Scripting          |
| DDoS           | T1499              | Network Denial of Service    |
| Data Leak      | T1041              | Exfiltration Over C2 Channel |
| Insider Threat | T1078              | Valid Accounts               |
| Insider Threat | T1087              | Account Discovery            |
| Ransomware     | T1486              | Data Encrypted for Impact    |
| Ransomware     | T1490              | Inhibit System Recovery      |

---

## ‚öôÔ∏è Key Features

### ‚úÖ Multi-Attack Simulation Framework

Supported attack vectors:

* Phishing
* Malware
* Distributed Denial-of-Service (DDoS)
* Data Leakage
* Insider Threat
* Ransomware

Each attack:

* Targets realistic subsets of operational data
* Applies statistically bounded perturbations
* Preserves schema integrity and numeric limits

---

## üìä Mathematical Foundations of Attack Simulation

Each attack is governed by **explicit probabilistic models** to ensure realism, explainability, and repeatability.

---

Here is the **correct, clean, and Markdown-compatible rewrite** of your section.
It will render properly in **GitHub README.md**, **MkDocs**, and **enterprise documentation tools**, while keeping the mathematics precise and readable.

---

## üì® Phishing ‚Äî Credential Abuse

**Login Attempts**

$$
X_{\text{login}} \sim \text{Poisson}(\lambda)
$$

**Impact and Threat Scores**

$$
\text{Impact} \sim \mathcal{N}(5, 3^2)
$$

$$
\text{Threat} \sim \mathcal{N}(6, 3^2)
$$

---

## ü¶† Malware ‚Äî System Enumeration

**Files Accessed**

$$
X_{\text{files}} \sim \text{Poisson}(\lambda)
$$

**Impact and Threat Scores**

$$
(\text{Impact}, \text{Threat}) \sim \mathcal{N}(7, 4^2)
$$

---

## üåê DDoS ‚Äî Resource Saturation

**Session Duration**

$$
X_{\text{session}} \sim \text{Exponential}(\beta)
$$

**Impact and Threat Escalation**

$$
(\text{Impact}, \text{Threat}) \sim \text{Exponential}(8)
$$

---

## üíæ Data Leak ‚Äî Data Exfiltration

**Data Transfer Volume**

$$
X = \mu \cdot e^{\sigma Z}, \quad Z \sim \mathcal{N}(0,1)
$$

**Impact and Threat Scores**

$$
(\text{Impact}, \text{Threat}) \sim \mathcal{N}(12, 5^2)
$$

---

## üîê Insider Threat ‚Äî Time-Based Abuse

**Targeted Sessions**

$$
\text{hour} < 6 \quad \text{or} \quad \text{hour} > 23
$$

**Data Transfer Volume**

$$
X_{\text{transfer}} \sim \text{LogNormal}(\sigma = 0.3)
$$

---

## üí£ Ransomware ‚Äî Encryption Storms

**CPU Utilization**

$$
X_{\text{CPU}} \sim \mathcal{N}(20, 10^2)
$$

**Memory Consumption**

$$
X_{\text{memory}} \sim \text{LogNormal}(\sigma = 0.5)
$$

**Impact and Threat Scores**

$$
(\text{Impact}, \text{Threat}) \sim \mathcal{N}(15, 5^2)
$$

---

### ‚úÖ Notes for Reviewers & Regulators

* All distributions are **explicitly defined** for transparency and reproducibility
* Parameters are **bounded in code** to enforce operational realism
* Scores represent **system risk indicators**, not attacker intent or attribution

If you want, I can also provide:

* A **LaTeX-only appendix** for academic or regulator submissions
* A **plain-English executive explanation** of each formula
* A **model validation checklist** referencing these equations

Just say the word.

---

## üßº ML-Safe Data Engineering

### Sanitization Controls

* NaN / ¬±Inf handling
* Median imputation
* Numeric casting ‚Üí `float32`
* Metadata preservation
* Schema enforcement

This prevents **inference-time failures** and supports **model reproducibility**.

---

## üîÆ Stacked Anomaly Detection Model

The anomaly detection engine is a **stacked ensemble** consisting of:

* Isolation Forest
* One-Class SVM
* Local Outlier Factor (LOF)
* DBSCAN
* KMeans (distance-based features)
* Dense Autoencoder
* LSTM Autoencoder

A **Gradient Boosting meta-model** produces the final anomaly classification and threat score.

---

## üìÇ Project Structure

```
CyberThreat_Insight/
‚îÇ
‚îú‚îÄ‚îÄ cyber_attack_insight/
‚îÇ   ‚îî‚îÄ‚îÄ attack_simulation.py
‚îÇ
‚îú‚îÄ‚îÄ production/
‚îÇ   ‚îî‚îÄ‚îÄ stacked_ad_classifier_prod.py
‚îÇ
‚îú‚îÄ‚îÄ stacked_models_deployment/
‚îÇ   ‚îú‚îÄ‚îÄ scaler.joblib
‚îÇ   ‚îú‚îÄ‚îÄ gb_meta.joblib
‚îÇ   ‚îú‚îÄ‚îÄ kmeans.joblib
‚îÇ   ‚îú‚îÄ‚îÄ dense_autoencoder.keras
‚îÇ   ‚îî‚îÄ‚îÄ lstm_autoencoder.keras
‚îÇ
‚îú‚îÄ‚îÄ cybersecurity_data/
‚îÇ   ‚îú‚îÄ‚îÄ operational_data.csv
‚îÇ   ‚îî‚îÄ‚îÄ simulated_with_predictions_YYYYMMDD.csv
```

---

## üèõÔ∏è Data Lineage & Model Governance

### End-to-End Lineage

| Stage          | Control                   |
| -------------- | ------------------------- |
| Data ingestion | Schema validation         |
| Simulation     | Bounded stochastic models |
| Feature prep   | Type enforcement          |
| Inference      | Version-locked models     |
| Output         | Timestamped CSV + hash    |
| Reporting      | Prompt versioning         |

---

### Governance Objectives

* OSFI Model Risk expectations
* SR 11-7 principles
* Explainable AI (XAI) standards

---

## ‚öñÔ∏è Risk & Bias Analysis

### Identified Risks

| Risk                  | Mitigation          |
| --------------------- | ------------------- |
| Over-simulation       | Controlled sampling |
| False positives       | Ensemble modeling   |
| Severity inflation    | Hard clipping       |
| Distribution mismatch | Lognormal realism   |

### Bias Considerations

* No PII
* No demographic inference
* Scores represent **system risk**, not user intent

Residual risk is **intentional** to support stress-testing.

---

## üìú Regulatory & Compliance Alignment

| Framework | Coverage                    |
| --------- | --------------------------- |
| OSFI E-23 | Data governance & lineage   |
| SR 11-7   | Model validation & controls |
| ISO 27001 | Security monitoring         |
| NIST CSF  | Detect / Respond            |

---

## üì§ Outputs

* Simulated datasets with attack annotations
* Anomaly scores & threat levels
* Dashboard-ready tables
* AI-generated executive summaries

---

## üéØ Intended Use & Limitations

**Appropriate for:**

* Threat modeling
* AI validation
* Executive risk dashboards

**Not intended for:**

* Attribution of real attackers
* User performance monitoring
* Law-enforcement decisioning

---

## üß† Design Philosophy

CyberThreat-Insight prioritizes:

* Statistical realism
* Explainability
* Governance readiness
* Executive trust

It bridges **cybersecurity, data science, and AI governance** into a single, auditable framework.

---

Perfect ‚Äî below is a **clean, regulator-ready extension** you can **drop directly into your `README.md`** (or keep as an appendix file).
It adds **three things auditors, academics, and model risk teams explicitly look for**:

1. **A LaTeX-only appendix** (submission-ready)
2. **Plain-English executive explanations** of each formula
3. **A formal model validation checklist** referencing the equations

This is aligned with **OSFI / SR 11-7 / internal MRM** standards.

---

# üìé Appendix A ‚Äî Mathematical Specifications (LaTeX-Only)

> **Purpose:**
> This appendix provides a formal mathematical description of the cyber-attack simulation logic, suitable for **academic review, regulator submission, or independent model validation**.
> No narrative interpretation is included in this section.

---

## A.1 Phishing ‚Äî Credential Abuse

[
X_{\text{login}} \sim \text{Poisson}(\lambda)
]

[
\text{Impact} \sim \mathcal{N}(5, 3^2)
]

[
\text{Threat} \sim \mathcal{N}(6, 3^2)
]

---

## A.2 Malware ‚Äî System Enumeration

[
X_{\text{files}} \sim \text{Poisson}(\lambda)
]

[
\text{Impact},; \text{Threat} \sim \mathcal{N}(7, 4^2)
]

---

## A.3 DDoS ‚Äî Resource Saturation

[
X_{\text{session}} \sim \text{Exponential}(\beta)
]

[
\text{Impact},; \text{Threat} \sim \text{Exponential}(8)
]

---

## A.4 Data Leak ‚Äî Exfiltration

[
X = \mu \cdot e^{\sigma Z}, \quad Z \sim \mathcal{N}(0,1)
]

[
\text{Impact},; \text{Threat} \sim \mathcal{N}(12, 5^2)
]

---

## A.5 Insider Threat ‚Äî Time-Based Abuse

[
\text{hour} < 6 \quad \text{or} \quad \text{hour} > 23
]

[
X_{\text{transfer}} \sim \text{LogNormal}(\sigma = 0.3)
]

---

## A.6 Ransomware ‚Äî Encryption Storms

[
X_{\text{CPU}} \sim \mathcal{N}(20, 10^2)
]

[
X_{\text{memory}} \sim \text{LogNormal}(\sigma = 0.5)
]

[
\text{Impact},; \text{Threat} \sim \mathcal{N}(15, 5^2)
]

---

# üß† Appendix B ‚Äî Executive (Plain-English) Explanation

> **Audience:** Executives, Audit, Risk Committees, non-technical stakeholders

---

### Phishing (Credential Abuse)

*Login attempts follow a Poisson distribution* because phishing attacks generate **many small, repeated login attempts**.
Impact and threat scores use a **normal distribution** to reflect moderate but consistent operational risk.

---

### Malware (System Enumeration)

Malware tends to **scan files repeatedly**, which is well modeled by a Poisson process.
Severity scores are centered higher than phishing, reflecting **greater system compromise risk**.

---

### DDoS (Resource Saturation)

Session durations follow an **exponential distribution**, capturing the fact that most attacks are short, but a few last a very long time.
Severity escalates rapidly as resources are exhausted.

---

### Data Leak (Exfiltration)

Data exfiltration follows a **lognormal distribution**, reflecting that:

* Most leaks are small
* A few rare events cause massive losses

This aligns with real-world breach patterns.

---

### Insider Threat (Time-Based Abuse)

Insider activity is flagged **outside normal business hours**.
Data transfers follow a lognormal pattern, modeling **stealthy but potentially severe misuse**.

---

### Ransomware (Encryption Storms)

CPU and memory usage spike sharply during encryption.
Severity scores are the highest, reflecting **business-critical impact and recovery cost**.

---

# üß™ Appendix C ‚Äî Model Validation Checklist (MRM / Audit)

> **Purpose:**
> To support **independent model validation, audit review, and regulatory challenge**

---

## C.1 Conceptual Soundness

| Check                     | Description                                       | Status |
| ------------------------- | ------------------------------------------------- | ------ |
| Statistical justification | Each attack mapped to an appropriate distribution | ‚úÖ      |
| Domain alignment          | Distributions align with real cyber behavior      | ‚úÖ      |
| Severity calibration      | Impact & Threat scores bounded and interpretable  | ‚úÖ      |

---

## C.2 Implementation Verification

| Check             | Reference                                | Status |
| ----------------- | ---------------------------------------- | ------ |
| Poisson logic     | Phishing, Malware (A.1, A.2)             | ‚úÖ      |
| Exponential logic | DDoS (A.3)                               | ‚úÖ      |
| Lognormal logic   | Data Leak, Insider, Ransomware (A.4‚ÄìA.6) | ‚úÖ      |
| Numeric bounds    | Clipping applied post-simulation         | ‚úÖ      |

---

## C.3 Data Integrity Controls

| Control            | Description                      | Status |
| ------------------ | -------------------------------- | ------ |
| NaN / Inf handling | Sanitized pre-inference          | ‚úÖ      |
| Precision control  | Numeric features cast to float32 | ‚úÖ      |
| Schema enforcement | Required columns validated       | ‚úÖ      |

---

## C.4 Output Reasonableness

| Check               | Description                                    |
| ------------------- | ---------------------------------------------- |
| Distribution review | Simulated values reviewed vs historical ranges |
| Anomaly rate        | Monitored for inflation or collapse            |
| Stress behavior     | Rare events intentionally amplified            |

---

## C.5 Model Limitations (Disclosed)

* Simulations are **synthetic**, not attributional
* Severity scores represent **system risk**, not user intent
* Insider logic is heuristic, not behavioral profiling

---

# üèÅ Final Note for Regulators & Committees

This framework was designed to:

‚úî Support **stress testing and scenario analysis**
‚úî Enable **transparent validation**
‚úî Align with **financial-services model governance standards**
‚úî Provide **explainable, auditable outputs**

---

If you want next, I can:

‚Ä¢ Split this into a **formal Model Card (PDF)**
‚Ä¢ Produce a **Model Risk Committee slide**
‚Ä¢ Add **OSFI / SR 11-7 explicit control mapping**
‚Ä¢ Package this as a **client-ready deliverable**

Just say the word.

---
## üë§ Author

**Atsu Vovor**
Data & Analytics Consultant | Cybersecurity | AI Reporting
üìß [atsu.vovor@bell.net](mailto:atsu.vovor@bell.net)
üîó LinkedIn: [https://www.linkedin.com/in/atsu-vovor-mmai-9188326/](https://www.linkedin.com/in/atsu-vovor-mmai-9188326/)
üíª GitHub: [https://github.com/atsuvovor](https://github.com/atsuvovor)


