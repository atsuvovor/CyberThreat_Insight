# Cyber Threat Detection Engine

<p align="center">
  <img src="https://github.com/atsuvovor/CyberThreat_Insight/blob/main/images/cyber_threat_detection_engine4.png"
       alt="Cyber Threat Detection Engine"
       style="width: 600px; height: auto;">
</p>

<p align="center"><strong>
Anomalous Behavior Detection in Cybersecurity Analytics using Generative AI
</strong></p>

**Location:** Toronto  \
**Date:** September 08, 2025  \
**Author:** Atsu Vovor

---

## Overview

The **Cyber Threat Detection Engine** is a hybrid machine learning framework designed to detect, classify, and prioritize cybersecurity threats by combining **unsupervised anomaly detection** with **supervised multi-class classification**.

Unlike traditional signature-based approaches, this engine focuses on **behavioral deviations** in security telemetry and leverages **Generative AI‚Äìaugmented data**, advanced feature engineering, and **stacked ensemble learning** to detect both known and emerging threats.

The target variable is **Threat Level**, defined as:

| Label | Threat Level |
|-----:|--------------|
| 0 | Low |
| 1 | Medium |
| 2 | High |
| 3 | Critical |

---

## Project Objectives

* Detect anomalous and malicious behavior in cybersecurity data
* Accurately classify threats into **four severity levels**
* Address the limitations of traditional unsupervised anomaly detection
* Combine anomaly sensitivity with supervised learning precision
* Enable real-world deployment readiness (scalable, explainable, extensible)

---

## End-to-End Architecture

The engine is structured as a modular pipeline:

1. **Data Ingestion & Synthetic Data Generation**  
2. **Feature Engineering & Normalization**  
3. **Unsupervised Anomaly Detection (Feature Generation)**  
4. **Supervised Classification (Stacked Ensemble)**  
5. **Model Evaluation & Visualization**  
6. **Deployment-Ready Artifact Packaging**

<p align="center">
  <img src="https://github.com/atsuvovor/CyberThreat_Insight/blob/main/images/stacked_anomaly_classifier_flowchart.png"
       alt="Stacked Anomaly Detection Pipeline"
       style="width: 100%; height: auto;">
</p>

---

## Data Ingestion & Augmentation

The engine is trained on an **augmented cybersecurity dataset** combining real telemetry with synthetically generated anomalies using:

* **Cholesky-based perturbation**
* **SMOTE (Synthetic Minority Over-sampling Technique)**
* **GANs (Generative Adversarial Networks)**

This approach mitigates class imbalance and strengthens detection of **rare but critical attack patterns**.

üîó Data Generator:
<a href="https://github.com/atsuvovor/CyberThreat_Insight/blob/main/datagen/README.md" target="_parent">
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

---

## Train‚ÄìTest Strategy

To ensure robust evaluation:

* **80% Training / 20% Testing split**
* **Stratified sampling** preserves threat-level distribution
* Fixed random seed for reproducibility

```python
X_train, X_test, y_train, y_test = train_test_split(
    X_augmented,
    y_augmented,
    test_size=0.2,
    random_state=42
)
```

---

## Feature Engineering

Features include:

* Behavioral metrics (frequency, duration, deviation)
* System-level indicators
* Network and access patterns
* **Anomaly scores generated by unsupervised models**

üîó Feature Engineering Module:
<a href="https://github.com/atsuvovor/CyberThreat_Insight/blob/main/feature_engineering/README.md" target="_parent">
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

---

## Models Implemented

### Unsupervised Models (Anomaly Detection)

| Model | Purpose |
|------|--------|
| Isolation Forest | Outlier isolation |
| One-Class SVM | Boundary-based anomaly detection |
| Local Outlier Factor (LOF) | Density deviation |
| DBSCAN | Density-based clustering |
| KMeans | Cluster distance analysis |
| Autoencoder | Reconstruction error |
| LSTM Autoencoder | Temporal anomaly detection |

### Supervised Models (Threat Classification)

| Model | Purpose |
|------|--------|
| Random Forest | Robust multi-class classification |
| Gradient Boosting | High-precision meta learner |
| Logistic Regression | Baseline comparison |
| Stacked Ensemble | Final production model |

---

## Key Challenge: Unsupervised Model Limitations

Unsupervised anomaly detection models:

* Predict **binary outputs only** (normal vs anomaly)
* Fail to distinguish between **High (2)** and **Critical (3)** threats
* Treat all anomalies as a single class

<p align="center">
  <img src="https://github.com/atsuvovor/CyberThreat_Insight/blob/main/images/models_confusion_matrix.png"
       alt="Unsupervised Model Confusion Matrix"
       style="width: 100%; height: auto;">
</p>

---

## Solution: Hybrid Stacked Architecture

### Core Idea

> **Use unsupervised models as feature generators, not final classifiers.**

### Anomaly Features Extracted

| Model | Feature |
|------|--------|
| Isolation Forest | Anomaly score |
| One-Class SVM | Anomaly flag |
| LOF | Density deviation |
| DBSCAN | Cluster membership |
| KMeans | Distance to centroid |
| Autoencoder | Reconstruction MSE |
| LSTM Autoencoder | Temporal error |

These features are concatenated with original inputs and passed into a **stacked supervised model**.

---

## Stacked Supervised Model

### Architecture

* **Base Learner:** Random Forest
* **Meta Learner:** Gradient Boosting

```python
stacked_model = StackingClassifier(
    estimators=[('rf', RandomForestClassifier())],
    final_estimator=GradientBoostingClassifier()
)
```

### Why Stacking Works

* Captures **rare anomaly signals**
* Improves recall for **High & Critical threats**
* Reduces false negatives

---

## Model Evaluation

### Metrics Used

* Accuracy
* Precision / Recall / F1-score (per class)
* Confusion Matrix
* ROC-AUC (binary anomaly components)

### Performance Summary

| Model | Accuracy | F1 (Class 3) | Recall (Class 3) |
|------|---------|--------------|------------------|
| Random Forest | 84% | 0.51 | 0.48 |
| Gradient Boosting | 83% | 0.49 | 0.46 |
| **Stacked Model** | **88%** | **0.61** | **0.59** |

---

## Deployment Readiness

### Saved Artifacts

* `scaler.joblib`
* `rf_base.joblib`
* `gb_meta.joblib`
* All unsupervised models (`iso`, `lof`, `ocsvm`, `dbscan`, `kmeans`)
* Autoencoder & LSTM models
* Metrics and evaluation reports

### Real-World Workflow

```
Incoming Logs
 ‚Üí Preprocessing
 ‚Üí Scaling
 ‚Üí Anomaly Feature Generation
 ‚Üí Feature Stacking
 ‚Üí Threat Level Prediction
 ‚Üí Alert / Response
```

<p align="center">
  <img src="https://github.com/atsuvovor/CyberThreat_Insight/blob/main/images/stacked_model.png"
       alt="Production Workflow"
       style="width: 80%; height: auto;">
</p>

---

## Use Cases

* SOC threat prioritization
* SIEM enrichment
* Insider threat detection
* Fraud and abuse monitoring
* Zero-day attack detection

---

## Conclusion

This Cyber Threat Detection Engine demonstrates that **hybrid ML architectures outperform standalone anomaly detectors**. By leveraging unsupervised models for signal extraction and supervised learning for classification, the system delivers:

* Improved detection of rare threats
* Full multi-class threat classification
* Production-ready scalability

This methodology is applicable beyond cybersecurity, including **fraud detection**, **risk monitoring**, and **operational anomaly detection**.

---

## Next Steps

‚û°Ô∏è Continue with the advanced stacked model implementation:

<a href="https://github.com/atsuvovor/CyberThreat_Insight/blob/main/model_dev/stacked_model/README.md" target="_parent">
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Next Step"/>
</a>

---

