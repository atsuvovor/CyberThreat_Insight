{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1rgoAbasoxYrRbjKmgXCooIzybs6AEcNh",
      "authorship_tag": "ABX9TyODgvTLDO4aHFVUxGGSB3iC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atsuvovor/CyberThreat_Insight/blob/main/model_dev/lagacy_best_model_dev/lagacy_model_dev_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CyberThreat-Insight**  \n",
        "\n",
        "**Anomalous Behavior Detection in Cybersecurity Analytics using Generative AI**\n",
        "\n",
        "**Toronto, Septeber 08 2025**  \n",
        "**Autor : Atsu Vovor**\n",
        ">Master of Management in Artificial Intelligence    \n",
        ">Consultant Data Analytics Specialist | Machine Learning |  \n",
        "Data science | Quantitative Analysis |French & English Bilingual"
      ],
      "metadata": {
        "id": "ZBkCWfxLiZFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# Model Development - Cyber Threat Detection Engine**\n",
        "\n",
        "The goal of this Model Development section is to build an effective cyber threat detection engine capable of identifying anomalous behavior in security log data. The target variable is **\"Threat Level\"**, classified as:  \n",
        "- 0 = Low  \n",
        "- 1 = Medium  \n",
        "- 2 = High  \n",
        "- 3 = Critical  \n",
        "\n",
        "This section details the full implementation, evaluation, and adaptation of both supervised and unsupervised learning models for detecting multi-class cyber threat levels. We first implement the following machine learning algorythms and select the model with the best performance. We then explore limitations of unsupervised anomaly detection models and propose a robust solution that adapts these models for multi-class classification.\n",
        "\n",
        "### Train-Test Split: Preparing for Model Evaluation\n",
        "\n",
        "Following feature engineering, we obtained an **augmented dataset** that combines the original cyber threat data with **synthetically generated anomalies** using techniques such as:\n",
        "\n",
        "* **Cholesky-based perturbation**\n",
        "* **SMOTE (Synthetic Minority Over-sampling Technique)**\n",
        "* **GANs (Generative Adversarial Networks)**\n",
        "\n",
        "This enriched dataset offers a **balanced distribution** of threat and non-threat instances, making it more suitable for supervised machine learning.\n",
        "\n",
        "### Objective\n",
        "\n",
        "To ensure robust model evaluation, we split the **augmented dataset** into training and testing subsets:\n",
        "\n",
        "* **Training Set (80%)**: Used to train models on both real and synthetic cyber threat patterns.\n",
        "* **Testing Set (20%)**: Used to validate performance on unseen data.\n",
        "\n",
        "We apply **stratified sampling** to maintain the class distribution across both subsets critical in cybersecurity where class imbalance (e.g., rare attacks) is a major challenge.\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "def deta_splitting(X_augmented, y_augmented, p_features_engineering_columns, target_column='Threat Level'):\n",
        "\n",
        "  x_features = [col for col in p_features_engineering_columns if col != target_column]\n",
        "\n",
        "  #Split the data into training and testing data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_augmented[x_features],\n",
        "    y_augmented,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        "  )\n",
        "\n",
        "```\n",
        "\n",
        "1. **Function Purpose:** The function `deta_splitting` facilitates the splitting of a dataset into training and testing subsets for machine learning purposes.\n",
        "2. **Test Size:** The `test_size=0.2` parameter ensures that 20% of the data is used for testing, while 80% is retained for training.\n",
        "3. **Reproducibility:** The `random_state=42` parameter guarantees consistent results across runs by fixing the randomness in data splitting.\n",
        "4. **Outputs:** The function returns four subsets:\n",
        "   - `X_train` and `y_train` for training the model.\n",
        "   - `X_test` and `y_test` for evaluating the model's performance.  \n",
        "\n",
        "\n",
        "\n",
        "## Models Implemented  \n",
        "\n",
        "\n",
        "| Algorithm                   | Type           | Description                                                                                          |\n",
        "|-----------------------------|----------------|------------------------------------------------------------------------------------------------------|\n",
        "| **Isolation Forest**        | Unsupervised   | Anomaly detection by isolating outliers through random partitioning of data.                         |\n",
        "| **One-Class SVM**           | Unsupervised   | Anomaly detection by identifying a region containing normal data points without labeled data.        |\n",
        "| **Local Outlier Factor (LOF)** | Unsupervised   | Detects outliers by comparing local data density with that of neighboring points.                     |\n",
        "| **DBSCAN**                  | Unsupervised   | Density-based clustering, also identifies outliers as noise.                                         |\n",
        "| **Autoencoder**             | Unsupervised   | A neural network used to learn compressed representations, often for anomaly detection.              |\n",
        "| **K-means Clustering**      | Unsupervised   | Clustering algorithm that partitions data into clusters without labels based on distance metrics.    |\n",
        "| **Random Forest**           | Supervised     | An ensemble of decision trees used for classification or regression with labeled data.               |\n",
        "| **Gradient Boosting**       | Supervised     | An ensemble method that builds sequential trees to improve prediction accuracy in classification or regression. |\n",
        "| **LSTM (Long Short-Term Memory)** | Supervised/Unsupervised | Typically supervised for sequence prediction tasks, but can also be used in unsupervised anomaly detection. |\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "While traditional classification metrics like accuracy, precision, recall, F1-score, ROC-AUC, and PR-AUC are primarily designed for binary classification problems, anomaly detection presents a unique challenge. In anomaly detection, the goal is to identify instances that deviate significantly from the normal pattern, rather than classifying them into predefined categories.\n",
        "\n",
        "**That said, we can adapt some of these metrics to evaluate anomaly detection models**  \n",
        "\n",
        "#### Applicable Metrics for Anomaly Detection\n",
        "\n",
        "1. **Precision, Recall, and F1-Score:**\n",
        "   - These metrics can be calculated by considering the true positive (TP), false positive (FP), true negative (TN), and false negative (FN) rates.\n",
        "   - However, the definition of \"positive\" and \"negative\" in anomaly detection can be ambiguous. Often, the minority class (anomalies) is considered positive.\n",
        "   - It's crucial to carefully define the positive and negative classes based on the specific use case and the desired outcome.\n",
        "\n",
        "2. **ROC-AUC and PR-AUC:**\n",
        "   - **ROC-AUC:** While it's commonly used for binary classification, it can be adapted to anomaly detection by treating anomalies as the positive class. However, the interpretation might be different.\n",
        "   - **PR-AUC:** This metric is particularly useful for imbalanced datasets, which is often the case in anomaly detection. It focuses on the precision-recall trade-off.\n",
        "\n",
        "3. **Confusion Matrix:**\n",
        "   - A confusion matrix can be constructed to visualize the performance of an anomaly detection model. However, the interpretation might differ from traditional classification.\n",
        "\n",
        "#### **Specific Considerations for Each Model**\n",
        "\n",
        "1. **Isolation Forest, OneClassSVM, Local Outlier Factor, DBSCAN:**\n",
        "   - These models directly output anomaly scores or labels.\n",
        "   - You can set a threshold to classify instances as anomalies or normal.\n",
        "   - Once you have the predicted labels, you can calculate the standard metrics.\n",
        "\n",
        "2. **Autoencoder:**\n",
        "   - Autoencoders are typically used for reconstruction-based anomaly detection.\n",
        "   - You can calculate the reconstruction error for each instance.\n",
        "   - A higher reconstruction error often indicates an anomaly.\n",
        "   - You can set a threshold on the reconstruction error to classify instances.\n",
        "   - Once you have the predicted labels, you can calculate the standard metrics.\n",
        "\n",
        "3. **LSTM:**\n",
        "   - LSTMs can be used for time series anomaly detection.\n",
        "   - You can train an LSTM to predict future values and calculate the prediction error.\n",
        "   - A higher prediction error often indicates an anomaly.\n",
        "   - You can set a threshold on the prediction error to classify instances.\n",
        "   - Once you have the predicted labels, you can calculate the standard metrics.\n",
        "\n",
        "4. **Augmented K-Means:**\n",
        "   - Augmented K-Means is a clustering-based anomaly detection technique.\n",
        "   - Instances that are far from cluster centers can be considered anomalies.\n",
        "   - You can set a distance threshold to classify instances.\n",
        "   - Once you have the predicted labels, you can calculate the standard metrics.\n",
        "\n",
        "## What Are the Models Predicting?  \n",
        "\n",
        "Supervised models were evaluated using classification metrics: accuracy, precision, recall, F1-score, and confusion matrices. We noticed that Random Forest and Gradient Boosting both predicted all 4 classes accurately.  \n",
        "Unsupervised models were originally evaluated by converting anomaly scores into binary labels (normal vs anomaly). However, they were only able to predict binary classes (typically class 0), failing to capture nuanced threat levels (2 and 3).  \n",
        "\n",
        "\n",
        "### Supervised Models  \n",
        "\n",
        "The supervised models directly predict the 'Threat Level' label and were able to classify all four\n",
        "categories correctly. Their success is due to the availability of labeled training data and the ability to\n",
        "learn decision boundaries across classes.\n",
        "\n",
        "* **Objective**: Learn to predict the threat level (`Risk Level`: Class 0–3) directly from labeled training data.\n",
        "* **Algorithms Used**:\n",
        "\n",
        "  * Random Forest\n",
        "  * Gradient Boosting\n",
        "  * Logistic Regression\n",
        "  * Stacking (Random Forest + Gradient Boosting)\n",
        "* **Target**: `Risk Level` (0: No Threat → 3: High Threat)\n",
        "* **Input**: Normalized features (numeric behavioral and system indicators)\n",
        "\n",
        "### Unsupervised Models  \n",
        "\n",
        "Unsupervised models like Isolation Forest, One-Class SVM, LOF, and DBSCAN are designed to distinguish anomalies from normal observations but not multiclass labels. These models predict binary labels (0 or 1). Class 0 indicates normal, class 1 indicates anomaly. When mapped against the threat\n",
        "levels, they mostly capture only class 0 or 1.\n",
        "\n",
        "* **Objective**: Detect anomalies in the data **without labels**, based on distance, density, or reconstruction error.\n",
        "* **Algorithms Used**:\n",
        "\n",
        "  * Isolation Forest\n",
        "  * One-Class SVM\n",
        "  * Local Outlier Factor (LOF)\n",
        "  * DBSCAN\n",
        "  * KMeans Clustering\n",
        "  * Autoencoder (Neural Network)\n",
        "  * LSTM (for sequential anomaly detection)\n",
        "* **Output**: Binary anomaly scores (0 = normal, 1 = anomaly), not multiclass predictions\n",
        "\n",
        "---\n",
        "\n",
        "## Class Prediction Gaps in Unsupervised Models\n",
        "\n",
        "### Observation:\n",
        "\n",
        "All unsupervised models **fail to distinguish between threat levels (Class 1, 2, 3)**. Most anomaly detection models only predict **Class 0** or flag minority of samples as \"anomalies\", making it difficult to classify **subtle threat patterns**.\n",
        "\n",
        "### Why Do Unsupervised Models Predict Only Class 0 for Class 2 and 3?\n",
        "\n",
        "Unsupervised anomaly models fail to predict higher threat levels because:\n",
        "- They are not trained with class labels and cannot distinguish among multiple classes.\n",
        "- Anomalies are rare, and severe anomalies (high threat) are even rarer.\n",
        "- These models generalize outliers as a single anomaly class (often mapped to class 1), unable to differentiate between moderate and critical threats.\n",
        "\n",
        "\n",
        "### Solution – Adaptation: Use Unsupervised Models as Feature Generators\n",
        "To overcome this limitation, we adopted a hybrid strategy:\n",
        "\n",
        "**Approach:** Generate anomaly features from each unsupervised model and include them as\n",
        "additional input features in a supervised learning pipeline.  \n",
        "\n",
        "**Implementation:** For each unsupervised model, the anomaly score or cluster assignment was extracted and added to the dataset. These enriched features were then used to train a stacked ensemble model combining Random Forest and Gradient Boosting.  \n",
        "\n",
        "**Result:** This strategy improved the model’s ability to predict all four threat levels, especially classes 2 and 3, which previously were missed by the unsupervised models alone\n",
        "\n",
        "\n",
        "##  Implementation: Stacked Supervised Model Using Anomaly Features\n",
        "\n",
        "### 1. Feature Engineering with Unsupervised Models\n",
        "\n",
        "**Unsupervised Models used as Feature Generators:**  \n",
        "\n",
        "| Algorithm        | Feature Extracted               |\n",
        "| ---------------- | ------------------------------- |\n",
        "| Isolation Forest | Anomaly score                   |\n",
        "| One-Class SVM    | Anomaly prediction              |\n",
        "| LOF              | Local density deviation score   |\n",
        "| DBSCAN           | Cluster membership or outlier   |\n",
        "| Autoencoder      | Reconstruction error            |\n",
        "| KMeans           | Cluster assignment              |\n",
        "| LSTM             | Time-series anomaly probability |\n",
        "\n",
        "These anomaly signals are treated as **auxiliary features** in the supervised pipeline.\n",
        "\n",
        "**Supervised Stack:**\n",
        "- Base: Random Forest Classifier\n",
        "- Meta: Gradient Boosting Classifier  \n",
        "\n",
        "### 2. Supervised Model Pipeline\n",
        "\n",
        "```python\n",
        "# Pseudo-structure\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y, test_size=0.2)\n",
        "\n",
        "# Define base and meta learners\n",
        "base_model = RandomForestClassifier()\n",
        "meta_model = GradientBoostingClassifier()\n",
        "\n",
        "stacked_model = StackingClassifier(\n",
        "    estimators=[('rf', base_model)],\n",
        "    final_estimator=meta_model\n",
        ")\n",
        "\n",
        "# Fit and evaluate\n",
        "stacked_model.fit(X_train, y_train)\n",
        "y_pred = stacked_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "```\n",
        "\n",
        "\n",
        "## Model Evaluation and Results\n",
        "\n",
        "### Evaluation Metrics:\n",
        "\n",
        "* Accuracy\n",
        "* Precision, Recall, F1-score (per class)\n",
        "* Confusion Matrix\n",
        "* ROC-AUC (if needed for binary components)\n",
        "\n",
        "### Key Observations:\n",
        "\n",
        "* Unsupervised models alone fail to predict classes 2 and 3 accurately.\n",
        "* Using anomaly scores as features improved supervised performance by:\n",
        "\n",
        "  * Enhancing signal for rare threat classes (Class 2, 3)\n",
        "  * Reducing false negatives (Class 0 misclassifications)  \n",
        "\n",
        "\n",
        "** Sample Evaluation Metrics**\n",
        "\n",
        "| Model                        | Accuracy | F1-Score (Class 3) | Recall (Class 3) |\n",
        "| ---------------------------- | -------- | ------------------ | ---------------- |\n",
        "| Random Forest Only           | 84%      | 0.51               | 0.48             |\n",
        "| Gradient Boosting Only       | 83%      | 0.49               | 0.46             |\n",
        "| **Stacked w/ Anomaly Feat.** | **88%**  | **0.61**           | **0.59**         |\n",
        "\n",
        "  \n",
        "  \n",
        "This stacked pipeline showed improved multiclass classification performance and better detection of critical threat levels.  \n",
        "\n",
        "\n",
        "## Model Selection and Deployment\n",
        "\n",
        "* **Selected Model**: StackingClassifier (RandomForest + GradientBoosting) with anomaly features\n",
        "* **Reason**: Best performance across threat levels, especially Class 3\n",
        "* **Deployment**: Model serialized and ready for inference; supports real-time scoring with anomaly-enriched feature vectors\n",
        "\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Using unsupervised models as **signal extractors** rather than classifiers proved effective. This hybrid approach leverages both:\n",
        "\n",
        "* The **anomaly sensitivity** of unsupervised models\n",
        "* The **targeted pattern learning** of supervised classifiers\n",
        "\n",
        "**Note:** This methodology is recommended for future applications in **cybersecurity, fraud detection**, or any anomaly-prone classification problem.\n"
      ],
      "metadata": {
        "id": "i55rfU5jTequ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/atsuvovor/CyberThreat_Insight.git 2>/dev/null\n",
        "%run /content/CyberThreat_Insight/model_dev/lagacy_best_model_dev/lagacy_model_dev.py"
      ],
      "metadata": {
        "id": "z-PJupo7ZG0J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}