{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMC09l7xSsX7X5jab6NlwCe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Certainly! Below is a Python script that integrates data augmentation using SMOTE and GANs, applies three anomaly detection algorithms (Isolation Forest, One-Class SVM, and Local Outlier Factor), and evaluates them to find the most effective method for detecting unauthorized access anomalies."],"metadata":{"id":"qIsZ7I2Se0aq"}},{"cell_type":"code","source":["#!pip install numpy pandas scikit-learn tensorflow imbalanced-learn"],"metadata":{"id":"IsOe8iCffu1g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Necessary libraries"],"metadata":{"id":"3qo7FT6vfe_A"}},{"cell_type":"code","source":[],"metadata":{"id":"562Ob1gQfUBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SeUT3qdCelyg"},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","from sklearn.ensemble import IsolationForest\n","from sklearn.svm import OneClassSVM\n","from sklearn.neighbors import LocalOutlierFactor\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from imblearn.over_sampling import SMOTE\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# 1. Simulate a sample dataset\n","data = {\n","    'Issue_ID': np.arange(1, 1001),\n","    'Category': np.random.choice(['Network', 'Access', 'Data Leak', 'Phishing', 'Malware'], 1000),\n","    'Severity': np.random.choice(['Low', 'Medium', 'High', 'Critical'], 1000),\n","    'Impact Score': np.random.randint(1, 11, 1000),\n","    'Risk Level': np.random.choice(['Low', 'Medium', 'High'], 1000),\n","    'User_ID': np.random.randint(1000, 2000, 1000),\n","    'Activity Type': np.random.choice(['login', 'file_access', 'data_modification'], 1000),\n","    'Session_Duration': np.random.normal(500, 200, 1000),\n","    'Data_Transfer_MB': np.random.normal(100, 50, 1000),\n","    'Login_Attempts': np.random.poisson(2, 1000)\n","}\n","df = pd.DataFrame(data)\n","\n","# 2. Data Preprocessing\n","label_encoders = {}\n","for column in ['Category', 'Severity', 'Risk Level', 'Activity Type']:\n","    le = LabelEncoder()\n","    df[column] = le.fit_transform(df[column])\n","    label_encoders[column] = le\n","\n","# Normalize numerical columns\n","scaler = StandardScaler()\n","df[['Impact Score', 'Session_Duration', 'Data_Transfer_MB', 'Login_Attempts']] = scaler.fit_transform(\n","    df[['Impact Score', 'Session_Duration', 'Data_Transfer_MB', 'Login_Attempts']])\n","\n","# 3. Address class imbalance using SMOTE\n","\n","X = df.drop(columns=['Issue_ID', 'User_ID'])\n","y = df['Risk Level']\n","display(X.head())\n","display(y.head())\n","smote = SMOTE(sampling_strategy='minority', random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(X, y)\n","\n","# 4. Synthetic data generation using GAN\n","latent_dim = 100\n","n_outputs = X_resampled.shape[1]\n","\n","def build_generator(latent_dim, n_outputs):\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(128, activation=\"relu\", input_dim=latent_dim))\n","    model.add(layers.Dense(256, activation=\"relu\"))\n","    model.add(layers.Dense(n_outputs, activation=\"tanh\"))\n","    return model\n","\n","def build_discriminator(n_outputs):\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(256, activation=\"relu\", input_shape=(n_outputs,)))\n","    model.add(layers.Dense(128, activation=\"relu\"))\n","    model.add(layers.Dense(1, activation=\"sigmoid\"))\n","    return model\n","\n","# Initialize models\n","generator = build_generator(latent_dim, n_outputs)\n","discriminator = build_discriminator(n_outputs)\n","discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# Train GAN\n","epochs = 1000\n","batch_size = 64\n","for epoch in range(epochs):\n","    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","    gen_data = generator.predict(noise)\n","\n","    idx = np.random.randint(0, X_resampled.shape[0], batch_size)\n","    real_data = X_resampled.iloc[idx].values\n","\n","    # Labels for real and generated data\n","    real_labels = np.ones((batch_size, 1))\n","    fake_labels = np.zeros((batch_size, 1))\n","\n","    d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n","    d_loss_fake = discriminator.train_on_batch(gen_data, fake_labels)\n","\n","    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","    g_loss = discriminator.train_on_batch(generator.predict(noise), real_labels)\n","\n","# 5. Concatenate SMOTE and GAN data to form the augmented dataset\n","synthetic_data = pd.DataFrame(gen_data, columns=X_resampled.columns)\n","X_augmented = pd.concat([X_resampled, synthetic_data], axis=0)\n","y_augmented = pd.concat([y_resampled, pd.Series(np.repeat(y_resampled.mode()[0], synthetic_data.shape[0]))])\n","\n","# 6. Anomaly Detection\n","\n","# Isolation Forest\n","iso_forest = IsolationForest(contamination=0.05, random_state=42)\n","iso_pred = iso_forest.fit_predict(X_augmented)\n","\n","# One-Class SVM\n","one_class_svm = OneClassSVM(kernel=\"rbf\", gamma=0.001, nu=0.05)\n","svm_pred = one_class_svm.fit_predict(X_augmented)\n","\n","# Local Outlier Factor\n","lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n","lof_pred = lof.fit_predict(X_augmented)\n","\n","# 7. Model Evaluation\n","# Convert -1 for anomalies, 1 for normal to binary labels for evaluation\n","def to_binary(predictions):\n","    return [0 if x == -1 else 1 for x in predictions]\n","\n","iso_pred_bin = to_binary(iso_pred)\n","svm_pred_bin = to_binary(svm_pred)\n","lof_pred_bin = to_binary(lof_pred)\n","\n","# Assume true labels for demonstration\n","true_labels = np.random.choice([0, 1], len(X_augmented), p=[0.95, 0.05])  # Randomly simulate true anomalies\n","\n","# Evaluate each model\n","models = {'Isolation Forest': iso_pred_bin, 'One-Class SVM': svm_pred_bin, 'Local Outlier Factor': lof_pred_bin}\n","best_model, best_f1 = None, 0\n","\n","for name, pred in models.items():\n","    precision = precision_score(true_labels, pred)\n","    recall = recall_score(true_labels, pred)\n","    f1 = f1_score(true_labels, pred)\n","    print(f\"{name} - Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n","\n","    if f1 > best_f1:\n","        best_f1 = f1\n","        best_model = name\n","\n","print(f\"\\nBest Model: {best_model} with F1 Score: {best_f1:.2f}\")\n","\n","\n"]},{"cell_type":"markdown","source":["### Explanation\n","\n","1. **Data Augmentation**:\n","   - We address class imbalance using **SMOTE** and **GAN** for synthetic data generation.\n","  \n","2. **Anomaly Detection**:\n","   - We apply three algorithms: **Isolation Forest**, **One-Class SVM**, and **Local Outlier Factor (LOF)**.\n","   - Each model is evaluated using `precision`, `recall`, and `F1 Score`.\n","\n","3. **Evaluation and Selection**:\n","   - The model with the highest `F1 Score` is chosen as the best approach to detect the security breach in our scenario.\n","\n","This setup should help in simulating and evaluating anomaly detection for critical cybersecurity events using real-world augmentation and detection methods."],"metadata":{"id":"u0qkyvJAe2Vc"}}]}